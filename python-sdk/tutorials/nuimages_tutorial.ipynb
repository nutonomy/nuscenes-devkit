{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nuImages devkit tutorial\n",
    "\n",
    "Welcome to the nuImages tutorial.\n",
    "This demo assumes the database itself is available at `/data/sets/nuimages`, and loads a mini version of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Gentle Introduction to nuImages\n",
    "\n",
    "In this part of the tutorial, let us go through a top-down introduction of our database. Our dataset is structured as a relational database with tables, tokens and foreign keys. The tables are the following:\n",
    "\n",
    "1. `log` - Log from which the sample was extracted.\n",
    "2. `sample` - An annotated camera image with an associated timestamp and past and future images and pointclouds.\n",
    "3. `sample_data` - An image or pointcloud associated with a sample.\n",
    "4. `ego_pose` - The vehicle ego pose and timestamp associated with a sample_data.\n",
    "5. `sensor` - General information about a sensor, e.g. `CAM_BACK_LEFT`.\n",
    "6. `calibrated_sensor` - Calibration information of a sensor in a log.\n",
    "7. `category` - Taxonomy of object and surface categories (e.g. `vehicle.car`, `flat.driveable_surface`). \n",
    "8. `attribute` - Property of an object that can change while the category remains the same.\n",
    "9. `object_ann` - Bounding box and mask annotation of an object (e.g. car, adult).\n",
    "10. `surface_ann` - Mask annotation of a surface (e.g. `flat.driveable surface` and `vehicle.ego`).\n",
    "\n",
    "The database schema is visualized below. For more information see the [schema page](https://github.com/nutonomy/nuscenes-devkit/blob/master/schema-nuimages.md).\n",
    "![](https://www.nuscenes.org/public/images/nuimages-schema.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nuImages Basics\n",
    "\n",
    "\n",
    "### Initialization\n",
    "To initialize the dataset class, we run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nuimages import NuImages\n",
    "\n",
    "nuim = NuImages(dataroot='/data/sets/nuimages', version='v1.0-val', verbose=True, lazy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the dataroot parameter if the dataset is installed in a different folder. We can also emit it to use the default setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables\n",
    "\n",
    "As described above, the NuImages class holds several tables. Each table is a list of records, and each record is a dictionary. For example the first record of the category table is stored at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuim.category[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the list of all tables, simply refer to the `table_names` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuim.table_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy loading\n",
    "\n",
    "Initializing the NuImages instance above was very fast, as we did not actually load the tables. Rather, the class implements lazy loading that overwrites the internal `__getattr__()` function to load a table if it is not already stored in memory. The moment we accessed `category`, we could see the table being loaded from disk. To disable such notifications, just set `verbose=False` when initializing the NuImages object. Furthermore lazy loading can be disabled with `lazy=False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "Since all tables are lists of dictionaries, we can use standard Python operations on them. A very common operation is to retrieve a particular record by its token. Since this operation takes linear time, we precompute an index that helps to access a record in constant time.\n",
    "\n",
    "Let us select the first image in this dataset version and split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = nuim.sample[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the sample record from a sample token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = nuim.get('sample', sample['token'])\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this does is actually to lookup the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = nuim.getind('sample', sample['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering\n",
    "\n",
    "To render an image we use the `render_image()` function. We can see the boxes and masks for each object category, as well as the surfaces masks for ego vehicle and driveable surface. At the top left corner of each box, we see the name of the object category. We use the following colors:\n",
    "- vehicles: orange\n",
    "- bicycles and motorcycles: red\n",
    "- pedestrians: blue\n",
    "- cones and barriers: black\n",
    "- driveable surface: teal / green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_token_camera = sample['key_camera_token']\n",
    "im = nuim.render_image(sd_token_camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every annotated image (sample) comes with up to 6 past and 6 future images, spaced evenly at 500ms +- 250ms.  For each image we have a matching lidar pointcloud. However, a small percentage of the samples has less sample_datas, either because they were at the beginning or end of a log, or due to delays or dropped data packages.\n",
    "`list_sample_content()` shows for each sample all the associated sample_datas, which are images (from the same camera) and lidar pointclouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuim.list_sample_content(sample['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the annotated images, we can also render the 6 previous and 6 future images, which are not annotated. Let's select the next image, which is around taken 0.5s after the annotated image. We can either manually copy the token from the list above or use the `next` pointer of the `sample_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_sd_token_camera = nuim.get('sample_data', sd_token_camera)['next']\n",
    "next_sd_token_camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the next token, let's render it. Note that we cannot render the annotations, as they don't exist.\n",
    "\n",
    "*Note: If you did not download the non-keyframes (sweeps), this will throw an error! We make sure to catch it here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    im = nuim.render_image(next_sd_token_camera, with_annotations=False)\n",
    "except Exception as e:\n",
    "    print('As expected, we encountered this error:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, most images have an associated lidar pointcloud. We can project this pointcloud to the image and display it using `render_depth()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuim.render_depth(sd_token_camera, mode='sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the pointcloud is relatively sparse, this image is hard to see. We can enable depth completion of the pointcloud to get a denser version of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuim.render_depth(sd_token_camera, mode='dense')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "\n",
    "The `list_*()` methods are useful to get an overview of the dataset dimensions. Note that these statistics are always *for the current split* that we initialized the `NuImages` instance with, rather than the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nuim.list_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`list_categories()` lists the category frequencies, as well as the category name and description. Each category is either an object or a surface, but not both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuim.list_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify a `sample_tokens` parameter for `list_categories()` to get the category statistics for a particular set of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tokens = [nuim.sample[9]['token']]\n",
    "nuim.list_categories(sample_tokens=sample_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`list_attributes()` shows the frequency, name and description of all attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuim.list_attributes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`list_cameras()` shows us how many camera entries and samples there are for each channel, such as the front camera.\n",
    "Each camera uses slightly different intrinsic parameters, which will be provided in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuim.list_cameras()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
